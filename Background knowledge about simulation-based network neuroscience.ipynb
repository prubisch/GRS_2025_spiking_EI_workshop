{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "408fe7e3",
   "metadata": {},
   "source": [
    "# Basics of simulation-based computational neuroscience\n",
    "\n",
    "\n",
    "This notebook introduces the principles and techniques of simulation-based network neuroscience. Simulation-based insights are particularly helpful when analytical solutions to neural models are intractable - typically due to non-linearities in the governing differential equations. A classic example is the reset of the membrane potential following a spike in simple spiking neuron models, which introduces a discontinuity not amenable to closed-form analysis. \n",
    "\n",
    "In neuroscience we want to model neural behaviour, and we have a plethora of neuron models to chose from to do so. They each vary in complexity, biological realism and computational cost. In general it is true that the higher the complexity of the model, the more computational resources are needed to simulate the system. Therefore, biological realism comes at the cost of computational effeciency. \n",
    "\n",
    "At one end are **rate-based models**, which represent neural activity as continuous firing rates. These models are computationally efficient can also often be analysed analytically, making them suitable for large-scale network analyses. The rate-based workshop will give you more information and insight into this. \n",
    "\n",
    "At the other end are detailed conductance-based models like the **Hodgkin-Huxley model**, which require numerical integration due to their complexity. In between are simplified spiking models like the **Leaky-Integrate and Fire (LIF) neuron**, which preserve spike-based computation while remaining computationally manageable. To simulate sych systems, we need to use numerical integration techniques; the most widely-used is the Euler method, which is also employed by simulation software such as BRIAN.\n",
    "\n",
    "\n",
    "# Numerical Integration: The Euler method\n",
    "\n",
    "Models in computational neuroscience are predominantely based on **(Ordinary) Differential Equations** (ODEs). Differential equations define the change of a system's state with respect to a certain quantity. In neuroscience, we often want to understand how the state of a neuron changes over time given an external stimulus or neuromodulation. Therefore neural ODEs or neural models define the change of neural activity $x$ (e.g. the rate or the membrane potential) over time: \n",
    "\\begin{align*}\\frac{dx}{dt} = f(x(t))\\end{align*}. \n",
    "where $x(t)$ denotes the neural state at time $t$ and $f(x(t))$ defines how the neural activity changes over the integration time step $t$. \n",
    "\n",
    "Given the differential equations of this form, we can simulate how the neural activity develops given an initial value $x(t=0)$ (also called the initial condition). We do this by calculating the successive neural states starting with our intial condition: \n",
    "\\begin{align*} x(t=1) &= x(t=0) + f(x(t=0)) \\\\ x(t=2) &= x(t=1) + f(x(t=1)) \\\\ &... \\\\ x(t=T) &= x(t=T-1) + f(x(t=T-1))\\end{align*}\n",
    "with $T$ being the last timestep we want to simulate. Formally the Euler method can be thus defined as \n",
    "\\begin{align*} x(t+Δt)=x(t)+Δt⋅f(x(t)) \\end{align*}. \n",
    "\n",
    "where $Δt$ is the integration time step. A smaller $Δt$ yields more accurate approximations but increases the number of steps required and thus the computational load.\n",
    "\n",
    "The graph below shows how the Euler method approximates a continuous trajectory. In this case we know the true form of $x(t)$ at each point. Therefore, we can see that if $Δt$ is large, the discrepancy between the true value and the approximation via the Euler method is large as well. Therefore, careful selection of $Δt$ is critical. For spiking neuron models, $Δt$= 0.1ms is a standard value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8704ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4a5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1251fe0c64941ed8b88d44bddbd2498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.1, description='dt:', max=0.2, min=0.01, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e1ad502473410ab3899f554bdd4275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def euler_method(dt,init, start, end, fun):\n",
    "\n",
    "    steps = int((end-start)/dt)\n",
    "    vals = np.arange(start, end+dt, dt)\n",
    "    vals[0] = init\n",
    "    for ind, v in enumerate(vals[:-1]):\n",
    "        vals[ind+1] = vals[ind] + dt * fun(vals[ind])\n",
    "\n",
    "    return vals\n",
    "\n",
    "def ODE(x):\n",
    "    return 2 * x\n",
    "\n",
    "def exact_solution(t):\n",
    "    return init_x * np.exp(2 * t)\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "init_x = 2\n",
    "\n",
    "# Function that generates and plots data based on the slider value\n",
    "def update_plot(value):\n",
    "\n",
    "    t = np.arange(start, end+value, value) # Example function using the slider value\n",
    "    x_approx = euler_method(value, init_x, start, end, ODE)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(t, exact_solution(t),color = 'grey')\n",
    "    plt.plot(t, x_approx, color = 'black', label = 'approximation')\n",
    "    plt.plot([0,value],[init_x,x_approx[0]], color = 'red', label = 'dt')\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('x')\n",
    "    plt.xlim(start, end)\n",
    "    plt.ylim(1.5, 15)\n",
    "    plt.title(f'Euler Integration with dt = {value:.3f}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider\n",
    "slider = widgets.FloatSlider(value=0.1, min=0.01, max=0.2, step=0.01, description=\"dt:\")\n",
    "\n",
    "# Use interactive to update the plot when the slider moves\n",
    "interactive_plot = widgets.interactive_output(update_plot, {'value': slider})\n",
    "\n",
    "# Display slider and interactive plot\n",
    "display(slider, interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5852e17",
   "metadata": {},
   "source": [
    "# Neuronal differential equations\n",
    "\n",
    "In this workshop you'll encounter two different types of neuron models: **rate-based neurons** and **spiking neurons**. As mentioned earlier, rate models can often be treated analytically, while spiking models can not. To see the differences in their formulation, we will demonstrate how to simulate them both using the Euler method. \n",
    "\n",
    "## Rate-based neurons\n",
    "\n",
    "A rate model abstracts the activity of a neuron as a continuous-valued _firing rate_, described by a single ODE. A typical rate neuron model is the following:\n",
    "\n",
    "$\\tau \\frac{dr}{dt} = -r + I(t)$\n",
    "\n",
    "where $r(t)$ is the firing rate of the neuron at time $t$, $\\tau$ is the time constant of integration, and $I(t)$ is an external input current or stimulus which can be turned on or off.\n",
    "\n",
    "We can rearrange and discretise this equation using the Euler method: \n",
    "\n",
    "\\begin{align*} \n",
    "r(t + \\Delta t) = r(t) + \\Delta t \\cdot \\left( \\frac{-r(t) + I(t)}{\\tau} \\right)\n",
    "\\end{align*}\n",
    "\n",
    "This allows us to simulate the time evolution of the firing rate numerically. Below is an interactive example. Use the sliders to explore how the firing rate responds to different stimulus strengths and durations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d8a247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc05f1dc98d0494bb2bd00ab818d1723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=10.0, description='strength:', step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae3a05cbb9a4494a1d9f770f4e3cf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=50.0, description='length[ms]:', max=90.0, min=1.0, step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fc227fd2324a4aae7da90f9aa8601c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rate_neuron(r, I, tau = 10):\n",
    "    return (-r + I)/tau\n",
    "\n",
    "def integrate(neuron, time, stimulus, dt = 0.1):\n",
    "    sim_time = int(time/dt)\n",
    "    r_act = np.zeros([sim_time+1]) #init activation is 0 here\n",
    "    t_record = np.zeros([sim_time])\n",
    "    I = 0\n",
    "    I_record =np.zeros([sim_time])\n",
    "\n",
    "    for t in range(sim_time):\n",
    "        if t > int(10/dt) and t < int(stimulus[1]/dt):\n",
    "            I = stimulus[0]\n",
    "        else:\n",
    "            I = 0\n",
    "        r_act[t+1] = r_act[t]+ dt * (rate_neuron(r_act[t],I))\n",
    "        t_record[t] = dt * t\n",
    "        I_record[t] = I\n",
    "\n",
    "    return r_act[:-1], t_record, I_record\n",
    "\n",
    "\n",
    "def update_rateplot(I_strength, I_duration ):\n",
    "\n",
    "    rates, ts, stim = integrate(rate_neuron, 100, [I_strength, I_duration]) #our time is in ms here\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(ts, rates,label = 'r')\n",
    "    plt.plot(ts, stim, color = 'grey', label = 'I')\n",
    "    plt.xlabel('t [ms]')\n",
    "    plt.ylabel('r [Hz]')\n",
    "    plt.title('Rate Neuron')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider\n",
    "slider = widgets.FloatSlider(value=10, min=0, max=100, step=1, description=\"strength:\")\n",
    "slider_l = widgets.FloatSlider(value=50, min=1, max=90, step=1, description=\"length[ms]:\")\n",
    "\n",
    "# Use interactive to update the plot when the slider moves\n",
    "interactive_plot = widgets.interactive_output(update_rateplot, {'I_strength': slider,'I_duration': slider_l})\n",
    "\n",
    "# Display slider and interactive plot\n",
    "display(slider, slider_l, interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf046336",
   "metadata": {},
   "source": [
    "A **spiking neuron model** differs from a rate-based model by explicitly modeling the generation of discrete spikes. In the **Leaky-Integrate and Fire (LIF) model**, this is implemented using a spike threshold and reset: when the neuron's membrane potential $v(t)$ surpasses a defined spike threshold $\\Theta_s$, a spike is said to occur, and the membrane potential is set to a reset potential - typically the resting potential $E_l$. \n",
    "\n",
    "This reset introduces a non-linearity to the system: the value of the membrane-potential after the reset does not follow linearly or continuously from its prior trajectory. As a result, the dynamics must be simulated numerically.\n",
    "\n",
    "Mathematically the LIF neuron is defined as:\n",
    "\n",
    "\\begin{align*} \\tau \\frac{dv}{dt} = (E_l - v) + I(t) \\\\\n",
    "if \\ \\ v(t) > \\Theta_s: v(t) \\leftarrow E_l \\end{align*}\n",
    "\n",
    "where $v$ is the neuron's membrane potential, $E_l$ is the resting potential, $\\tau$ is the membrane time constant, $I(t)$ is the external input current, and $\\Theta_s$ is the spiking threshold.\n",
    "\n",
    "This minimal model captures the essential feature of spike generation. More sophisticated variants exist which include, for example, differential equations for after-spike reset currents to model refractory periods, and adaptive thresholds to model spike-threshold adaption.\n",
    "\n",
    "Below you can vary the received input to visualise its effect on the subthreshold membrane dynamics and the resulting spiking pattern. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967959d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4caf7b4dee495699b37c135c75415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=10.0, description='strength:', step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7025fdab3142028d7a65446ec0b140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=50.0, description='length [ms]:', max=90.0, min=1.0, step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373480a3fa6543539b9bb5ec86cd9fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def LIF_neuron(v, I, Theta_s=-50, E_L=-70, tau=10):\n",
    "    if v < Theta_s:\n",
    "        return ((E_L - v) + I) / tau\n",
    "    else:\n",
    "        return E_L  # immediate reset, we do not approximate the spike form here\n",
    "\n",
    "def integrate(neuron, time, stimulus, dt=0.1):\n",
    "    sim_time = int(time / dt)\n",
    "    v_act = np.zeros(sim_time + 1) - 70  # initial potential set to E_L\n",
    "    t_record = np.zeros(sim_time)\n",
    "    I_record = np.zeros(sim_time)\n",
    "\n",
    "    for t in range(sim_time):\n",
    "        if t > int(10 / dt) and t < int(stimulus[1] / dt):  # define stimulus window\n",
    "            I = stimulus[0]\n",
    "        else:\n",
    "            I = 0\n",
    "        v_act[t + 1] = v_act[t] + dt * neuron(v_act[t], I)\n",
    "        t_record[t] = dt * t\n",
    "        I_record[t] = I\n",
    "\n",
    "    return v_act[:-1], t_record, I_record, np.nonzero(v_act[:-1] >= -50)[0]\n",
    "\n",
    "def update_rateplot(I_strength, I_duration):\n",
    "    vs, ts, stim, spikes = integrate(LIF_neuron, 100, [I_strength, I_duration])  # time in ms\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(ts, vs, label='v')\n",
    "    plt.scatter(ts[spikes], np.full_like(spikes, -45), color='r')\n",
    "    plt.plot(ts, stim, color='grey', label='I')\n",
    "    plt.xlabel('t [ms]')\n",
    "    plt.ylabel(r'$V_m$ [mV]')\n",
    "    plt.title('LIF Neuron')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "slider = widgets.FloatSlider(value=10, min=0, max=100, step=1, description=\"strength:\")\n",
    "slider_l = widgets.FloatSlider(value=50, min=1, max=90, step=1, description=\"length [ms]:\")\n",
    "\n",
    "interactive_plot = widgets.interactive_output(update_rateplot, {'I_strength': slider, 'I_duration': slider_l})\n",
    "\n",
    "display(slider, slider_l, interactive_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fd311",
   "metadata": {},
   "source": [
    "# Noise\n",
    "\n",
    "To drive neural activity, one can either inject a constant external stimulus or noise into the neuron. Simulating noise has the advantage that it approximates the aggregate synaptic input from many presynaptic neurons that one does not need to model explicitly. \n",
    "\n",
    "A commonly-used form of noisy current $\\eta(t)$ is modelled as an **Ornstein-Uhlenbeck (OU) process**. OU noise resembles a random walk with a restoring force: it integrates a Wiener process $\\frac{dW}{dt}$ (time-step-adjusted white noise) over time. It is defined as: \n",
    "\\begin{align*}\n",
    "\\tau \\frac{d\\eta}{dt} = \\theta \\cdot (\\mu - \\eta) + \\sigma \\underbrace{\\frac{dW}{dt}}_{\\text{Wiener process}} \n",
    "\\end{align*}\n",
    " where:\n",
    " - $\\mu$ is the mean value around which the process fluctuates\n",
    " - $\\theta$ controls the rate at which $\\eta(t)$ is pulled back towards $\\mu$\n",
    " - $\\sigma$ sets the amplitude of the fluctuations (the standard deviation)\n",
    " - $\\tau$ determines the characteristic timescale of the fluctuations\n",
    " \n",
    "The larger the $\\sigma$, the greater the deviations from the mean. The larger the $\\tau$, the slower the fluctuations. The drive $\\theta$ governs how fast the OU process returns to $\\mu$ after a perturbation. \n",
    "\n",
    "In practice, we simulate this stochastic differential equation using the Euler-Maruyama method, which gives the following equation:\n",
    "\\begin{align*}\n",
    "\\eta(t+1) = \\eta(t) + \\frac{\\Delta t}{\\tau} \\theta (\\mu - \\eta) + \\sigma \\underbrace{\\sqrt{\\frac{2 \\Delta t}{\\tau}}\\cdot N(0,1)}_{\\text{Wiener process}}\n",
    "\\end{align*}\n",
    "\n",
    "The square-root scaling of the Wiener term is necessary to ensure that the magnitude of the fluctuations remains constant regardless of the spread $\\sigma$ and the integration time step $\\tau$.\n",
    "\n",
    "Below, you can explore how the activity of a rate neuron and a LIF neuron differ depending on the **mean** and **standard deviation** of the OU noise. For simplicity, we set $ \\theta = 1$, which is therefore omitted from the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9626e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b8ffb45faf45539345dece0e30356f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='μ:', min=-20.0, step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaa7512d03c48e8857de2ebacecc225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=2.0, description='σ:', max=20.0, min=0.1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48288b91940248bc82c612d16fb4ff24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def integrate(time, stimulus, dt=0.1, tau=20):\n",
    "    rng = np.random.RandomState(seed=5)  # fixed seed for reproducibility\n",
    "    sim_time = int(time / dt)\n",
    "\n",
    "    v_act = np.zeros(sim_time + 1) - 70  # initial membrane potential (E_L)\n",
    "    r_act = np.zeros(sim_time + 1)       # initial rate activity\n",
    "    t_record = np.zeros(sim_time)        # time array\n",
    "    I = np.full(sim_time + 1, stimulus[0])  # initialize at mean value\n",
    "\n",
    "    for t in range(sim_time):\n",
    "        I[t + 1] = I[t] + (dt / tau) * (stimulus[0] - I[t]) + np.sqrt(2 * dt / tau) * stimulus[1] * rng.randn()\n",
    "        v_act[t + 1] = v_act[t] + dt * LIF_neuron(v_act[t], I[t])\n",
    "        r_act[t + 1] = r_act[t] + dt * rate_neuron(r_act[t], I[t])\n",
    "        t_record[t] = dt * t\n",
    "\n",
    "    return v_act[:-1], r_act[:-1], t_record, I[:-1]\n",
    "\n",
    "\n",
    "def update_noiseplot(mean, sigma):\n",
    "    vs, rs, ts, stim = integrate(100, [mean, sigma])  # simulation over 100 ms\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(6, 6))\n",
    "\n",
    "    ax[0].plot(ts, stim)\n",
    "    ax[0].plot(ts, np.full_like(ts, mean), color='grey', linestyle=':')\n",
    "    ax[0].set_xlabel('t [ms]')\n",
    "    ax[0].set_ylabel(r'$\\eta(t)$  [mV]')\n",
    "    ax[0].set_title('OU Noise')\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    ax[1].plot(ts, rs)\n",
    "    ax[1].plot(ts, np.zeros_like(ts), color='grey', linestyle=':')\n",
    "    ax[1].set_xlabel('t [ms]')\n",
    "    ax[1].set_ylabel(r'$r (t)$  [Hz]')\n",
    "    ax[1].set_title('Rate Neuron')\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    ax[2].plot(ts, vs)\n",
    "    ax[2].plot(ts, np.full_like(ts, -70), color='grey', linestyle=':')\n",
    "    ax[2].set_xlabel('t [ms]')\n",
    "    ax[2].set_ylabel(r'$V_m$  [mV]')\n",
    "    ax[2].set_title('LIF Neuron')\n",
    "    ax[2].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "# Create a slider\n",
    "slider_mu = widgets.FloatSlider(value=0, min=-20, max=100, step=1, description=\"μ:\")\n",
    "slider_sigma = widgets.FloatSlider(value=2, min=0.1, max=20, step=0.1, description=\"σ:\")\n",
    "\n",
    "# Use interactive to update the plot when the slider moves\n",
    "interactive_plot = widgets.interactive_output(update_noiseplot, {'mean': slider_mu, 'sigma': slider_sigma})\n",
    "\n",
    "# Display slider and interactive plot\n",
    "display(slider_mu, slider_sigma, interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf94da55",
   "metadata": {},
   "source": [
    "# Simulation modules & packages\n",
    "\n",
    "So far, we have programmed every detail of the system ourselves. However, this is not strictly neccessary. There are plenty of Python packages specifically designed for simulating dynamical systems and neural networks. This means that you don't have to take care of implementational details, but rather just to define your model, network architecture, and - if wished - integration method. This allows you to simulate large networks without having to manually optimise for computational performance, since the packages are already tuned for speed and scaleability. \n",
    "\n",
    "Using dedicated simulation libraries can mitigate the trade-off between model complexity and computational cost. Choosing the right package can help speed up your simulations significantly; some options include **Neuron**, **Nest**, **BRIAN**, and **Dendrify**, to name a few. \n",
    "\n",
    "In the following section, we'll show you how to implement the above noisy neuron using **BRIAN**. During the **Spiking Neural Network Tutorial** we'll continue to use this package, since its intuitive syntax makes network configuration easy to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc17430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "from brian2tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0492572b",
   "metadata": {},
   "source": [
    "To define a model in **BRIAN**, you have to specify it as a differential equation of the form: \n",
    "\n",
    "```differential_equation = dx/dt = dif(x) : unit```\n",
    "\n",
    "The *unit* must always be given in SI units. **BRIAN** automatically checks your differential equations for unit compatibility. This means you'll get an error if, for example, an equation defining membrane potential dynamics does not conform to the expected units of volts per second $(V/s)$, or if you try to add a variable in Hertz to one in Amperes. This feature is particularly helpful when converting between units.\n",
    "\n",
    "However, you don't have to specify units; you can also define **dimensionless** variables by assigning them a unit of $1$. \n",
    "\n",
    "You can add neural attributes by specifying the variable after the differential equation:\n",
    "```variable:unit```\n",
    "\n",
    "For example, you can specify the membrane time constant this way, and give each neuron in your network a different time constant by setting it explicitly. Below, you'll find the definitions for:\n",
    "- a dimensionless rate neuron,\n",
    "- a rate neuron whose activity is measured explicitly in Hertz,\n",
    "- a spiking LIF neuron.\n",
    "\n",
    "Any variable that depends on time - like ```I_rate(t), I[t], I_spike(t)``` - is treated as an external, time-dependent input. These inputs are not part of the neuron's internal dynamics, but are provided separately. They can be used to deliver square pulses or repeated stimulus patterns into the neuron, without having to stop the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023a81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca08273f5f24d74b46ebbf3ff565fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=10.0, description='duration:', step=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ff613277584bf8a858c9d6150e4eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=50.0, description='amplitude:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516e86d4228342acb87dd1ecad0cbb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Differential equations\n",
    "# Dimensionless rate neuron\n",
    "diff_eq_rate = '''dr/dt = (-r + I_rate(t))/tau : 1\n",
    "                  tau : second'''\n",
    "\n",
    "# Frequency rate neuron \n",
    "diff_eq_rate_Hz = '''dr/dt = (-r + I[t])/tau : Hz\n",
    "                     tau : second'''\n",
    "\n",
    "# LIF neuron\n",
    "diff_eq_spike = '''dv/dt = ((E_L - v) + I_spike(t))/tau : volt (unless refractory)\n",
    "                   E_L : volt\n",
    "                   v_spike : volt\n",
    "                   tau : second'''\n",
    "\n",
    "\n",
    "def run_brian_neurons(length, strength):\n",
    "    start_scope()  # clears previous Brian objects to avoid duplication\n",
    "\n",
    "    # Define neurons\n",
    "    N_rate = NeuronGroup(1, diff_eq_rate, method='euler')\n",
    "    N_rate.tau = 10 * ms\n",
    "\n",
    "    N_spike = NeuronGroup(1, diff_eq_spike,\n",
    "                          threshold='v > v_spike',\n",
    "                          reset='v = E_L',\n",
    "                          refractory=3 * ms,\n",
    "                          method='euler')\n",
    "    N_spike.E_L = -79 * mV\n",
    "    N_spike.v_spike = -49 * mV\n",
    "    N_spike.v = -79 * mV  # set initial condition (we need to define v(0) otherwise it is assumed to be 0)\n",
    "    N_spike.tau = 10 * ms\n",
    "\n",
    "    # Define input stimulus (200 ms total duration, stimulus begins at 10ms)\n",
    "    input_arr = np.zeros(200)\n",
    "    onset = 10  # ms\n",
    "    input_arr[onset:int(length) + onset] = strength\n",
    "\n",
    "    # Define time-dependent input as TimedArray\n",
    "    I_rate = TimedArray(input_arr, dt=1 * ms)   # each entry in the TimedArray lasts for 1ms\n",
    "    I_spike = TimedArray(input_arr * mV, dt=1 * ms)   # needs to be in mV to be compatible with dimensions of the model (with proper consideration of conductances we could also inject a current here)\n",
    "\n",
    "    # To record neuron activity, we need to define monitors\n",
    "    # Syntax: StateMonitor(group to record from, variable to record, which neurons to record from, recording frequency)\n",
    "    s_v = SpikeMonitor(N_spike)\n",
    "    record_r = StateMonitor(N_rate, 'r', record=True, dt=1 * ms)\n",
    "    record_v = StateMonitor(N_spike, 'v', record=True, dt=1 * ms)\n",
    "    record_I = input_arr \n",
    "\n",
    "    run(500 * ms, report='text') # Run the network for 500ms; you can delete the status report by omitting the second argument in the function\n",
    "\n",
    "    return s_v, record_r, record_v, record_I\n",
    "\n",
    "\n",
    "def update_brianplot(stim_l, stim_s):\n",
    "    spikemon, rec_r, rec_v, input_arr = run_brian_neurons(stim_l, stim_s)\n",
    "\n",
    "    t_input = np.arange(len(input_arr))  # 0 to 199 ms\n",
    "\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(6, 7))\n",
    "\n",
    "    # Plot stimulus\n",
    "    ax[0].plot(t_input, input_arr, color='grey')\n",
    "    ax[0].set_ylabel('I')\n",
    "    ax[0].set_title('Input Current')\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot rate neuron\n",
    "    ax[1].plot(rec_r.t / ms, rec_r.r[0])\n",
    "    ax[1].set_xlabel('t [ms]')\n",
    "    ax[1].set_ylabel(r'$r$')\n",
    "    ax[1].set_title('Rate Neuron')\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    # Plot LIF neuron\n",
    "    ax[2].plot(rec_v.t / ms, rec_v.v[0] / mV)\n",
    "    ax[2].scatter(spikemon.t / ms, np.full_like(spikemon.t, -45), color='r') # If you want to plot a spike raster you can use SpikeMonitor\n",
    "    ax[2].set_xlabel('t [ms]')\n",
    "    ax[2].set_ylabel(r'$v$ [mV]')\n",
    "    ax[2].set_title('LIF Neuron')\n",
    "    ax[2].grid(True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "# Create sliders\n",
    "slider = widgets.FloatSlider(value=10, min=0, max=100, step=1, description=\"duration:\")\n",
    "slider_l = widgets.FloatSlider(value=50, min=0, max=100, step=0.1, description=\"amplitude:\")\n",
    "\n",
    "# Set up interactivity\n",
    "interactive_plot = widgets.interactive_output(update_brianplot, {'stim_l': slider, 'stim_s': slider_l})\n",
    "\n",
    "# Display slider and interactive plot\n",
    "display(slider, slider_l, interactive_plot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
